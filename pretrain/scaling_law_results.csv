experiment_id,model.d_model,model.d_ff,model.num_layers,model.num_heads,training.train_steps,model_size_params,training_tokens,batch_size,iterations,train_loss,valid_loss
1,704,2048,9,11,1120,56770560,293601280,262144,1120,3.187,2.9511842970278863
2,640,1792,8,10,1565,40632320,410255360,262144,1565,3.0796,2.826378590284573
3,576,1536,7,9,2281,27869184,597950464,262144,2281,3.1065,2.736298184727658
4,512,1472,6,8,3202,19857408,839385088,262144,3202,2.8239,2.681913272586432
5,448,1344,6,7,4061,15654912,1064566784,262144,4061,2.9237,2.6637178683545337
experiment_id,model.d_model,model.d_ff,model.num_layers,model.num_heads,training.train_steps,model_size_params,training_tokens,batch_size,iterations,train_loss,valid_loss
1,896,2240,11,14,1,101556224,262144,262144,1878,2.9465,3.324051856994629
2,768,2048,10,12,2695,70778880,706478080,262144,2695,2.988,3.1253445943196616
3,704,1728,9,11,3763,50688000,986447872,262144,3763,2.6348,3.0124731063842773
4,640,1728,7,10,5498,34693120,1441267712,262144,5498,2.5961,2.850209871927897
5,576,1536,7,9,6844,27869184,1794113536,262144,6844,2.9374,2.7708422342936196
experiment_id,model.d_model,model.d_ff,model.num_layers,model.num_heads,training.train_steps,model_size_params,training_tokens,batch_size,iterations,train_loss,valid_loss
1,704,2048,9,11,1120,56770560,293601280,262144,1120,3.1577,3.2221206029256186
2,640,1792,8,10,1565,40632320,410255360,262144,1565,2.9744,3.0870993932088218
3,576,1536,7,9,2281,27869184,597950464,262144,2281,3.0038,2.933373133341471
4,512,1472,6,8,3202,19857408,839385088,262144,3202,2.825,2.848064740498861
5,448,1344,6,7,4061,15654912,1064566784,262144,4061,2.8896,2.8122545878092446
experiment_id,model.d_model,model.d_ff,model.num_layers,model.num_heads,training.train_steps,model_size_params,training_tokens,batch_size,iterations,train_loss,valid_loss
1,704,2048,9,11,1120,56770560,293601280,262144,1120,3.0905,3.154939651489258
2,640,1792,8,10,1565,40632320,410255360,262144,1565,2.926,3.0214033126831055
3,576,1536,7,9,2281,27869184,597950464,262144,2281,3.0268,2.946254094441732
4,512,1472,6,8,3202,19857408,839385088,262144,3202,2.8501,2.867857297261556
5,448,1344,6,7,4061,15654912,1064566784,262144,4061,2.9077,2.821811040242513
experiment_id,model.d_model,model.d_ff,model.num_layers,model.num_heads,training.train_steps,model_size_params,training_tokens,batch_size,iterations,train_loss,valid_loss
1,896,2240,11,14,1878,101556224,492306432,262144,1878,2.948,3.024669329325358
2,768,2048,10,12,2695,70778880,706478080,262144,2695,2.925,2.912560145060221
3,704,1728,9,11,3763,50688000,986447872,262144,3763,2.7432,2.8360678354899087
4,640,1728,7,10,5498,34693120,1441267712,262144,5498,2.7737,2.716611862182617
5,576,1536,7,9,6844,27869184,1794113536,262144,6844,2.756,2.655454476674398
experiment_id,model.d_model,model.d_ff,model.num_layers,model.num_heads,training.train_steps,model_size_params,training_tokens,batch_size,iterations,train_loss,valid_loss
1,1024,2880,14,8,1714,182583296,1797259264,524288,1714,2.7476,2.7471171034672426
2,960,2496,12,15,2436,130498560,2554331136,524288,2436,2.8042,2.6925827086049545
3,832,2496,10,13,7065,89989120,1852047360,262144,7065,2.6854,2.834609349568685
4,768,2048,9,12,9981,63700992,2616459264,262144,9981,2.6182,2.7060912450154624
5,704,1856,9,11,11969,53121024,3137601536,262144,11969,2.7284,2.647815704345703
